{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeonardChiu567/mgmt467-analytics-portfolio/blob/main/Lab(2)_VertexAI_BigQuery_PromptsOnly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ecd5d16",
      "metadata": {
        "id": "4ecd5d16"
      },
      "source": [
        "# Lab: Vertex AI–Assisted BigQuery Analytics — Example Prompts\n",
        "**Goal:** Practice moving from simple SQL to complex analytics in BigQuery using *only* carefully engineered prompts with Vertex AI (Gemini).  \n",
        "**Important:** This notebook contains **prompts only** (no starter code). Paste the prompts into **Vertex AI Studio**, **Vertex AI in Colab Enterprise**, or your chosen chat interface, and then run the generated SQL directly in **BigQuery**. If you decide to automate later, you can ask Vertex AI to convert the winning SQL into a Colab pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8a8d5cd",
      "metadata": {
        "id": "b8a8d5cd"
      },
      "source": [
        "## How to use this prompts-only notebook\n",
        "1. Open **Vertex AI Studio** (or Gemini in Colab Enterprise chat panel).  \n",
        "2. Copy a prompt from this notebook and paste it into the model. Do **not** paste any code from here; let the model generate it.  \n",
        "3. Run the generated SQL in **BigQuery** (Console → BigQuery Studio).  \n",
        "4. Iterate: refine the prompt when results aren’t what you expect.  \n",
        "5. Document: capture your final SQL, plus a one-sentence takeaway, in your notes/README."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e967d4a7",
      "metadata": {
        "id": "e967d4a7"
      },
      "source": [
        "## Dataset assumptions\n",
        "Use one of these sources (adjust table paths accordingly):\n",
        "- **Global Superstore (Kaggle)** loaded into BigQuery (e.g., `[YOUR_PROJECT].superstore_data.sales`)  \n",
        "- **TheLook eCommerce** public dataset: `bigquery-public-data.thelook_ecommerce`  \n",
        "If you are using *Global Superstore*, make sure column names match your schema (e.g., `Order_Date`, `Region`, `Category`, `Sub_Category`, `Sales`, `Profit`, `Discount`, `State`, `Customer_ID`, `Ship_Mode`)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5940720",
      "metadata": {
        "id": "f5940720"
      },
      "source": [
        "---\n",
        "## Prompting guardrails (quick checklist)\n",
        "- **Be explicit**: table path, column names, filters, output columns, sort order, and limits.  \n",
        "- **Ask for runnable SQL**: “Return a BigQuery SQL block only.”  \n",
        "- **Control cost**: ask for `LIMIT` during exploration and remove it for the final run.  \n",
        "- **Validate**: request a brief explanation of why each clause is present and how you can sanity-check results.\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "deGHQK9Tm7Rq"
      },
      "id": "deGHQK9Tm7Rq"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Google Cloud BigQuery client library\n",
        "!pip install google-cloud-bigquery==3.17.0 pandas==2.1.4\n",
        "\n",
        "# Authenticate your Colab environment\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "C75yp0ekYtNl",
        "outputId": "6524c931-5ec6-45cc-b0f1-7b23ba23ab1a"
      },
      "id": "C75yp0ekYtNl",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-cloud-bigquery==3.17.0\n",
            "  Downloading google_cloud_bigquery-3.17.0-py2.py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting pandas==2.1.4\n",
            "  Downloading pandas-2.1.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery==3.17.0) (2.25.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery==3.17.0) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery==3.17.0) (2.7.2)\n",
            "Requirement already satisfied: packaging>=20.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery==3.17.0) (25.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery==3.17.0) (2.9.0.post0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery==3.17.0) (2.32.4)\n",
            "Collecting numpy<2,>=1.26.0 (from pandas==2.1.4)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.1.4) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.1.4) (2025.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery==3.17.0) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery==3.17.0) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery==3.17.0) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery==3.17.0) (2.38.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.12/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery==3.17.0) (1.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery==3.17.0) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery==3.17.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery==3.17.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery==3.17.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery==3.17.0) (2025.8.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery==3.17.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery==3.17.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery==3.17.0) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery==3.17.0) (0.6.1)\n",
            "Downloading google_cloud_bigquery-3.17.0-py2.py3-none-any.whl (230 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.2/230.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.1.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, pandas, google-cloud-bigquery\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: google-cloud-bigquery\n",
            "    Found existing installation: google-cloud-bigquery 3.38.0\n",
            "    Uninstalling google-cloud-bigquery-3.38.0:\n",
            "      Successfully uninstalled google-cloud-bigquery-3.38.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.4 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "bigframes 2.21.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.17.0 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "xarray 2025.9.0 requires pandas>=2.2, but you have pandas 2.1.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-cloud-bigquery-3.17.0 numpy-1.26.4 pandas-2.1.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "36fe7b430da54dc19b06d1ac37973d92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3950993508.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Authenticate your Colab environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Authenticated'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output, project_id)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0m_gcloud_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m       \u001b[0m_install_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0m_check_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CredentialType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m   \u001b[0;32mraise\u001b[0m \u001b[0m_errors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAuthorizationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Failed to fetch user credentials'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36m_check_adc\u001b[0;34m(credential_type)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ServiceAccountCredentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mcreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Failure refreshing credentials: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/auth/compute_engine/credentials.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             self.token, self.expiry = _metadata.get_service_account_token(\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mservice_account\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_service_account_email\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscopes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscopes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/auth/compute_engine/_metadata.py\u001b[0m in \u001b[0;36mget_service_account_token\u001b[0;34m(request, service_account, scopes)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"instance/service-accounts/{0}/token\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice_account\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m     \u001b[0mtoken_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m     token_expiry = _helpers.utcnow() + datetime.timedelta(\n\u001b[1;32m    373\u001b[0m         \u001b[0mseconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"expires_in\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/auth/compute_engine/_metadata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(request, path, root, params, recursive, retry_count, headers, return_none_for_not_found_error)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackoff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders_to_use\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_RETRYABLE_STATUS_CODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 _LOGGER.warning(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, url, method, body, headers, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Making request: %s %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             response = self.session.request(\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy Schema to a dataframe"
      ],
      "metadata": {
        "id": "jxAyMbWZnEe0"
      },
      "id": "jxAyMbWZnEe0"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "\n",
        "# Replace with your Google Cloud Project ID\n",
        "project_id = 'mgmt-467-4677' # This is derived from your provided table name\n",
        "dataset_id = 'lab1_foundation'\n",
        "table_id = 'superstore'\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "# Get the table object\n",
        "table_ref = client.dataset(dataset_id).table(table_id)\n",
        "table = client.get_table(table_ref)\n",
        "\n",
        "# Extract schema information\n",
        "schema_list = []\n",
        "for field in table.schema:\n",
        "    schema_list.append({\n",
        "        'name': field.name,\n",
        "        'field_type': field.field_type,\n",
        "        'mode': field.mode,\n",
        "        'description': field.description\n",
        "    })\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "schema_df = pd.DataFrame(schema_list)\n",
        "\n",
        "# Display the schema DataFrame (optional, for verification)\n",
        "print(\"Schema DataFrame created:\")\n",
        "# To see the output, run the code.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "Pdp4EpOIY93w",
        "outputId": "bd602bdd-95f8-4336-c16e-ab74c2fde707"
      },
      "id": "Pdp4EpOIY93w",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFound",
          "evalue": "404 GET https://bigquery.googleapis.com/bigquery/v2/projects/mgmt-467-4677/datasets/lab1_foundation/tables/superstore?prettyPrint=false: Not found: Dataset mgmt-467-4677:lab1_foundation",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4047868863.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Get the table object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtable_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Extract schema information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36mget_table\u001b[0;34m(self, table, retry, timeout)\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0mspan_attributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m         api_response = self._call_api(\n\u001b[0m\u001b[1;32m   1080\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0mspan_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"BigQuery.getTable\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    825\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspan_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspan_attributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m             ):\n\u001b[0;32m--> 827\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/_http/__init__.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpect_json\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFound\u001b[0m: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/mgmt-467-4677/datasets/lab1_foundation/tables/superstore?prettyPrint=false: Not found: Dataset mgmt-467-4677:lab1_foundation"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLean Column Names"
      ],
      "metadata": {
        "id": "QkdVGvHZnNNn"
      },
      "id": "QkdVGvHZnNNn"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Clean the Column Names ---\n",
        "# Create a 'clean_name' column with standard naming conventions:\n",
        "# lowercase, with spaces and hyphens replaced by underscores.\n",
        "schema_df['clean_name'] = schema_df['name'].str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
        "\n",
        "\n",
        "# --- 2. Generate the Aliases for the SELECT Clause ---\n",
        "column_expressions = []\n",
        "for index, row in schema_df.iterrows():\n",
        "    original_name = row['name']\n",
        "    clean_name = row['clean_name']\n",
        "\n",
        "    # If the original name contains a space or special character, it needs to be\n",
        "    # enclosed in backticks (`) in the SQL statement.\n",
        "    if ' ' in original_name or '-' in original_name:\n",
        "        expression = f'`{original_name}` AS {clean_name}'\n",
        "    else:\n",
        "        # If the name is already clean, we still alias it for consistency.\n",
        "        expression = f'{original_name} AS {clean_name}'\n",
        "    column_expressions.append(expression)\n",
        "\n",
        "# Join all the individual column expressions into a single, formatted string.\n",
        "select_clause = \",\\n  \".join(column_expressions)\n",
        "\n",
        "\n",
        "# --- 3. Construct the Final CREATE VIEW Statement ---\n",
        "new_view_id = 'superstore_clean' # You can change this if you like\n",
        "\n",
        "create_view_sql = f\"\"\"\n",
        "CREATE OR REPLACE VIEW `{project_id}.{dataset_id}.{new_view_id}` AS\n",
        "SELECT\n",
        "  {select_clause}\n",
        "FROM\n",
        "  `{project_id}.{dataset_id}.{table_id}`;\n",
        "\"\"\"\n",
        "\n",
        "# --- 4. Print the Final SQL ---\n",
        "print(\"--- Copy the SQL below and run it in your BigQuery Console ---\")\n",
        "print(create_view_sql)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "hjxWwOPYgyu3",
        "outputId": "01b90e8c-0429-4a6f-eef2-61dbc79864a6"
      },
      "id": "hjxWwOPYgyu3",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'schema_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-495695760.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Create a 'clean_name' column with standard naming conventions:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# lowercase, with spaces and hyphens replaced by underscores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mschema_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschema_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'schema_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate View with standard column naming convention"
      ],
      "metadata": {
        "id": "Av6ZsQoIhw7v"
      },
      "id": "Av6ZsQoIhw7v"
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the CREATE VIEW SQL query\n",
        "try:\n",
        "    query_job = client.query(create_view_sql)  # API request\n",
        "    query_job.result()  # Waits for the query to finish\n",
        "    print(f\"View '{new_view_id}' created/replaced successfully in dataset '{dataset_id}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while creating the view: {e}\")\n",
        "\n",
        "# Now, let's print 10 rows from the newly created view to verify\n",
        "print(f\"\\n--- First 10 rows from the new view '{new_view_id}' ---\")\n",
        "try:\n",
        "    # Construct a reference to the new view\n",
        "    view_table_ref = client.dataset(dataset_id).table(new_view_id)\n",
        "\n",
        "    # Fetch the first 10 rows\n",
        "    rows = client.list_rows(view_table_ref, max_results=10)\n",
        "\n",
        "    # Print header\n",
        "    print(\" | \".join([field.name for field in rows.schema]))\n",
        "    print(\"-\" * 80) # Separator\n",
        "\n",
        "    # Print rows\n",
        "    for row in rows:\n",
        "        print(\" | \".join([str(item) for item in row.values()]))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while fetching rows from the view: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "xoMmfxY2hOOg",
        "outputId": "5b23ca66-5fe0-4b9d-e7c7-fbcc54b9a502"
      },
      "id": "xoMmfxY2hOOg",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred while creating the view: name 'create_view_sql' is not defined\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'new_view_id' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3217711526.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Now, let's print 10 rows from the newly created view to verify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n--- First 10 rows from the new view '{new_view_id}' ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Construct a reference to the new view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'new_view_id' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This assumes your 'client' object from the previous cell is still active\n",
        "# and correctly authenticated.\n",
        "\n",
        "print(\"✅ Step 1: Defining the query string...\")\n",
        "\n",
        "query_string = \"\"\"\n",
        "SELECT\n",
        "  order_id,\n",
        "  customer_name,\n",
        "  product_name,\n",
        "  sales,\n",
        "  profit\n",
        "FROM\n",
        "  `mgmt-467-47888.lab1_foundation.superstore_clean`\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "\n",
        "print(\"✅ Step 2: Sending the query to BigQuery. This may take a moment...\")\n",
        "\n",
        "# Use a try-except block to catch potential errors\n",
        "try:\n",
        "    query_job = client.query(query_string)\n",
        "\n",
        "    print(\"✅ Step 3: Waiting for query to complete and fetching results...\")\n",
        "    results_df = query_job.to_dataframe()\n",
        "\n",
        "    print(f\"✅ Step 4: Query finished. Found {len(results_df)} rows.\")\n",
        "\n",
        "    if results_df.empty:\n",
        "        print(\"\\n⚠️ The query ran successfully but returned an empty result. Please double-check that your 'superstore_clean' view exists and the original table has data.\")\n",
        "    else:\n",
        "        print(\"\\n--- Displaying Results ---\")\n",
        "        display(results_df)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BDjVOddXjBvS",
        "outputId": "bbbb04ed-5a08-4902-dbdf-57ebffca6a2e"
      },
      "id": "BDjVOddXjBvS",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Step 1: Defining the query string...\n",
            "✅ Step 2: Sending the query to BigQuery. This may take a moment...\n",
            "✅ Step 3: Waiting for query to complete and fetching results...\n",
            "\n",
            "❌ An error occurred: 403 Access Denied: Table mgmt-467-47888:lab1_foundation.superstore_clean: User does not have permission to query table mgmt-467-47888:lab1_foundation.superstore_clean, or perhaps it does not exist.; reason: accessDenied, message: Access Denied: Table mgmt-467-47888:lab1_foundation.superstore_clean: User does not have permission to query table mgmt-467-47888:lab1_foundation.superstore_clean, or perhaps it does not exist.\n",
            "\n",
            "Location: US\n",
            "Job ID: a7d8abf4-8c15-475f-b8e0-fb538ffc938a\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I-aQV1fUlLsh"
      },
      "id": "I-aQV1fUlLsh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vpNaruc0gxgO"
      },
      "id": "vpNaruc0gxgO"
    },
    {
      "cell_type": "markdown",
      "id": "21fdd1b4",
      "metadata": {
        "id": "21fdd1b4"
      },
      "source": [
        "## Part A — SQL Warm‑Up (SELECT, WHERE, ORDER BY, LIMIT, DISTINCT)\n",
        "**Aim:** Build confidence with precise, unambiguous prompts that yield clean, runnable SQL."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d51345cd",
      "metadata": {
        "id": "d51345cd"
      },
      "source": [
        "### A1. Unique values (DISTINCT)\n",
        "**Prompt (paste in Vertex AI):**\n",
        "```\n",
        "Act as a senior BigQuery analyst. Produce a **single runnable BigQuery SQL** (no commentary) for:\n",
        "- Task: List all unique `Sub_Category` values sold in the 'West' region.\n",
        "- Table: `mgmt-467-47888.lab1_foundation.superstore`\n",
        "- Filter: `Region = 'West'`\n",
        "- Output: a single column named `Sub_Category`\n",
        "- Sort: alphabetically A→Z\n",
        "- Add: `LIMIT 100` to control cost during exploration.\n",
        "```\n",
        "**Reflection:** Did the result match your expectations? If not, what ambiguity in your prompt might have caused the mismatch?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_string = \"\"\"\n",
        "SELECT\n",
        "    DISTINCT `Sub-Category` AS Sub_Category\n",
        "FROM\n",
        "    `mgmt-467-47888.lab1_foundation.superstore_clean`\n",
        "WHERE\n",
        "    Region = 'West'\n",
        "ORDER BY\n",
        "    Sub_Category ASC\n",
        "LIMIT 100\n",
        "\"\"\"\n",
        "results_df = query_job.to_dataframe()\n",
        "display(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "FIjfmUFEiMA4",
        "outputId": "cec9268a-26f4-4833-c382-3f2a6714b026"
      },
      "id": "FIjfmUFEiMA4",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Forbidden",
          "evalue": "403 Access Denied: Table mgmt-467-47888:lab1_foundation.superstore_clean: User does not have permission to query table mgmt-467-47888:lab1_foundation.superstore_clean, or perhaps it does not exist.; reason: accessDenied, message: Access Denied: Table mgmt-467-47888:lab1_foundation.superstore_clean: User does not have permission to query table mgmt-467-47888:lab1_foundation.superstore_clean, or perhaps it does not exist.\n\nLocation: US\nJob ID: a7d8abf4-8c15-475f-b8e0-fb538ffc938a\n\n\nLocation: US\nJob ID: a7d8abf4-8c15-475f-b8e0-fb538ffc938a\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2252981028.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mLIMIT\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \"\"\"\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mto_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype)\u001b[0m\n\u001b[1;32m   1890\u001b[0m                 \u001b[0;34m:\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mshapely\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mlibrary\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mimported\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1891\u001b[0m         \"\"\"\n\u001b[0;32m-> 1892\u001b[0;31m         \u001b[0mquery_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait_for_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1893\u001b[0m         return query_result.to_dataframe(\n\u001b[1;32m   1894\u001b[0m             \u001b[0mbqstorage_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbqstorage_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/_tqdm_helpers.py\u001b[0m in \u001b[0;36mwait_for_query\u001b[0;34m(query_job, progress_bar_type, max_results)\u001b[0m\n\u001b[1;32m    102\u001b[0m     )\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprogress_bar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1593\u001b[0m                 \u001b[0mdo_get_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_get_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m             \u001b[0mdo_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGoogleAPICallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mdo_get_result\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1582\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job_retry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_retry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1584\u001b[0;31m                 \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1586\u001b[0m                 \u001b[0;31m# Since the job could already be \"done\" (e.g. got a finished job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mDEFAULT_RETRY\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"retry\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_AsyncJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcancelled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout, retry, polling)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;31m# pylint: disable=raising-bad-type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;31m# Pylint doesn't recognize that this is valid in this case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2772855207.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Step 3: Waiting for query to complete and fetching results...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"✅ Step 4: Query finished. Found {len(results_df)} rows.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mto_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype)\u001b[0m\n\u001b[1;32m   1890\u001b[0m                 \u001b[0;34m:\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mshapely\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mlibrary\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mimported\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1891\u001b[0m         \"\"\"\n\u001b[0;32m-> 1892\u001b[0;31m         \u001b[0mquery_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait_for_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1893\u001b[0m         return query_result.to_dataframe(\n\u001b[1;32m   1894\u001b[0m             \u001b[0mbqstorage_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbqstorage_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/_tqdm_helpers.py\u001b[0m in \u001b[0;36mwait_for_query\u001b[0;34m(query_job, progress_bar_type, max_results)\u001b[0m\n\u001b[1;32m    102\u001b[0m     )\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprogress_bar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1593\u001b[0m                 \u001b[0mdo_get_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_get_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m             \u001b[0mdo_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGoogleAPICallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mdo_get_result\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1582\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job_retry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_retry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1584\u001b[0;31m                 \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1586\u001b[0m                 \u001b[0;31m# Since the job could already be \"done\" (e.g. got a finished job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mDEFAULT_RETRY\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"retry\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_AsyncJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcancelled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout, retry, polling)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;31m# pylint: disable=raising-bad-type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;31m# Pylint doesn't recognize that this is valid in this case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mForbidden\u001b[0m: 403 Access Denied: Table mgmt-467-47888:lab1_foundation.superstore_clean: User does not have permission to query table mgmt-467-47888:lab1_foundation.superstore_clean, or perhaps it does not exist.; reason: accessDenied, message: Access Denied: Table mgmt-467-47888:lab1_foundation.superstore_clean: User does not have permission to query table mgmt-467-47888:lab1_foundation.superstore_clean, or perhaps it does not exist.\n\nLocation: US\nJob ID: a7d8abf4-8c15-475f-b8e0-fb538ffc938a\n\n\nLocation: US\nJob ID: a7d8abf4-8c15-475f-b8e0-fb538ffc938a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6d69d23",
      "metadata": {
        "id": "d6d69d23"
      },
      "source": [
        "### A2. Top‑N by metric (ORDER BY … DESC)\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: Return the top 10 customers by total profit.\n",
        "Table: `mgmt-467-47888.lab_foundation.superstore`\n",
        "Columns used: `Customer_ID`, `Profit`\n",
        "Output columns: `Customer_ID`, `total_profit`\n",
        "Logic: SUM Profit per customer, order by `total_profit` DESC\n",
        "Add `LIMIT 10`.\n",
        "```\n",
        "**Tip:** If your schema uses different identifiers (e.g., `Customer Name`), restate column names explicitly."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SELECT\n",
        "  Customer_ID,\n",
        "  SUM(Profit) AS total_profit\n",
        "FROM\n",
        "  `mgmt-467-47888.lab_foundation.superstore`\n",
        "GROUP BY\n",
        "  Customer_ID\n",
        "ORDER BY\n",
        "  total_profit DESC\n",
        "LIMIT 10;\n"
      ],
      "metadata": {
        "id": "vqbTkZhxXyCf"
      },
      "id": "vqbTkZhxXyCf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f4a477d4",
      "metadata": {
        "id": "f4a477d4"
      },
      "source": [
        "### A3. Basic filtering (WHERE) + sanity checks\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: Count orders shipped with each `Ship_Mode`, but only for orders in the 'Technology' category.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "Output: `Ship_Mode`, `order_count`\n",
        "Logic: COUNT(*) grouped by `Ship_Mode`\n",
        "Sort by `order_count` DESC\n",
        "```\n",
        "**Validation ask:** “Also list two quick sanity checks to verify the numbers.”"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SELECT\n",
        "  Ship_Mode,\n",
        "  COUNT(*) AS order_count\n",
        "FROM\n",
        "  `[YOUR_PROJECT].superstore_data.sales`\n",
        "WHERE\n",
        "  Category = 'Technology'\n",
        "GROUP BY\n",
        "  Ship_Mode\n",
        "ORDER BY\n",
        "  order_count DESC;\n"
      ],
      "metadata": {
        "id": "bH_O96uCeacP"
      },
      "id": "bH_O96uCeacP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "51afdc05",
      "metadata": {
        "id": "51afdc05"
      },
      "source": [
        "## Part B — Grouped Analytics (GROUP BY, HAVING)\n",
        "**Aim:** Turn raw facts into grouped metrics and filtered aggregations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10c5933e",
      "metadata": {
        "id": "10c5933e"
      },
      "source": [
        "### B1. KPI aggregation with WHERE + GROUP BY\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: Compute monthly revenue for the last 12 full months.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "Assume: `Order_Date` is a DATE or TIMESTAMP column named exactly `Order_Date`.\n",
        "Output: `year_month` (YYYY-MM format), `monthly_revenue`\n",
        "Logic: Truncate date to month, SUM `Sales`, filter to last 12 full months.\n",
        "Sort by `year_month` ascending.\n",
        "Include a `LIMIT` safeguard for exploration.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SELECT\n",
        "  FORMAT_DATE('%Y-%m', DATE_TRUNC(Order_Date, MONTH)) AS year_month,\n",
        "  SUM(Sales) AS monthly_revenue\n",
        "FROM\n",
        "  `[YOUR_PROJECT].superstore_data.sales`\n",
        "WHERE\n",
        "  Order_Date >= DATE_SUB(DATE_TRUNC(CURRENT_DATE(), MONTH), INTERVAL 12 MONTH)\n",
        "  AND Order_Date < DATE_TRUNC(CURRENT_DATE(), MONTH)\n",
        "GROUP BY\n",
        "  year_month\n",
        "ORDER BY\n",
        "  year_month ASC\n",
        "LIMIT 50;\n"
      ],
      "metadata": {
        "id": "xy4uCRsRehCA"
      },
      "id": "xy4uCRsRehCA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "15d75d03",
      "metadata": {
        "id": "15d75d03"
      },
      "source": [
        "### B2. Post‑aggregation filter (HAVING)\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: Find sub-categories whose total profit over the entire dataset is negative.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "Output: `Sub_Category`, `total_profit`\n",
        "Logic: SUM `Profit` GROUP BY `Sub_Category`, HAVING SUM(Profit) < 0\n",
        "Sort by `total_profit` ASC (most negative first).\n",
        "```\n",
        "**Why HAVING?** Ask the model to include a 1-sentence explanation of why HAVING is used instead of WHERE here."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SELECT\n",
        "  Sub_Category,\n",
        "  SUM(Profit) AS total_profit\n",
        "FROM\n",
        "  `[YOUR_PROJECT].superstore_data.sales`\n",
        "GROUP BY\n",
        "  Sub_Category\n",
        "HAVING\n",
        "  SUM(Profit) < 0\n",
        "ORDER BY\n",
        "  total_profit ASC;\n",
        "#HAVING is used instead of WHERE because it filters results after aggregation, allowing us to apply a condition on the summed Profit for each Sub_Category."
      ],
      "metadata": {
        "id": "Lykylr88esdW"
      },
      "id": "Lykylr88esdW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bbd28071",
      "metadata": {
        "id": "bbd28071"
      },
      "source": [
        "## Part C — Joins (dimension enrichment)\n",
        "**Aim:** Use joins to enhance facts with attributes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7736534",
      "metadata": {
        "id": "e7736534"
      },
      "source": [
        "### C1. Join facts to a small dimension\n",
        "*(If you have a customer or product dimension in your schema, use it. Otherwise, request a synthetic example.)*  \n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: Join the sales table to a product dimension to report `Product_ID`, `Product_Name`, and total sales.\n",
        "Tables: `[YOUR_PROJECT].superstore_data.sales` as s, `[YOUR_PROJECT].superstore_data.products` as p\n",
        "Join key: `s.Product_ID = p.Product_ID`\n",
        "Output: `Product_ID`, `Product_Name`, `total_sales`\n",
        "Sort by `total_sales` DESC\n",
        "```\n",
        "**If you lack a dimension table:** Ask the model how to simulate one temporarily via a CTE."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SELECT\n",
        "  s.Product_ID,\n",
        "  p.Product_Name,\n",
        "  SUM(s.Sales) AS total_sales\n",
        "FROM\n",
        "  `[YOUR_PROJECT].superstore_data.sales` AS s\n",
        "JOIN\n",
        "  `[YOUR_PROJECT].superstore_data.products` AS p\n",
        "ON\n",
        "  s.Product_ID = p.Product_ID\n",
        "GROUP BY\n",
        "  s.Product_ID,\n",
        "  p.Product_Name\n",
        "ORDER BY\n",
        "  total_sales DESC;\n"
      ],
      "metadata": {
        "id": "Ogk_CIoOexFs"
      },
      "id": "Ogk_CIoOexFs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "dca07c5a",
      "metadata": {
        "id": "dca07c5a"
      },
      "source": [
        "## Part D — Common Table Expressions (CTEs)\n",
        "**Aim:** Make complex logic readable and testable in steps."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b268567f",
      "metadata": {
        "id": "b268567f"
      },
      "source": [
        "### D1. Multi‑step ranking with CTEs\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Goal: Within each `Region`, rank states by total sales and return top 3 per region.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "CTE 1 (`state_sales`): SUM(Sales) by `Region`, `State`\n",
        "CTE 2 (`ranked_state_sales`): Add `RANK() OVER (PARTITION BY Region ORDER BY total_sales DESC)` as `sales_rank`\n",
        "Final SELECT: rows where `sales_rank <= 3`\n",
        "Output columns: `Region`, `State`, `total_sales`, `sales_rank`\n",
        "Sort: by `Region`, then `sales_rank`\n",
        "```\n",
        "**Ask for**: a one-paragraph explanation of each step, then **provide only the final runnable SQL**."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WITH state_sales AS (\n",
        "  SELECT\n",
        "    Region,\n",
        "    State,\n",
        "    SUM(Sales) AS total_sales\n",
        "  FROM\n",
        "    `[YOUR_PROJECT].superstore_data.sales`\n",
        "  GROUP BY\n",
        "    Region,\n",
        "    State\n",
        "),\n",
        "ranked_state_sales AS (\n",
        "  SELECT\n",
        "    Region,\n",
        "    State,\n",
        "    total_sales,\n",
        "    RANK() OVER (PARTITION BY Region ORDER BY total_sales DESC) AS sales_rank\n",
        "  FROM\n",
        "    state_sales\n",
        ")\n",
        "SELECT\n",
        "  Region,\n",
        "  State,\n",
        "  total_sales,\n",
        "  sales_rank\n",
        "FROM\n",
        "  ranked_state_sales\n",
        "WHERE\n",
        "  sales_rank <= 3\n",
        "ORDER BY\n",
        "  Region,\n",
        "  sales_rank;\n"
      ],
      "metadata": {
        "id": "ABZkdNR5e2pD"
      },
      "id": "ABZkdNR5e2pD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "46a39db5",
      "metadata": {
        "id": "46a39db5"
      },
      "source": [
        "### D2. Time‑boxed “most improved” analysis\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Goal: Identify the top 5 sub-categories with the largest YoY revenue increase from 2023 to 2024.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "CTE `yr_sales`: SUM(Sales) by `Sub_Category` and `year` extracted from `Order_Date`\n",
        "Final: pivot or self-join to compute delta (2024 minus 2023) as `yoy_delta`\n",
        "Output: `Sub_Category`, `sales_2023`, `sales_2024`, `yoy_delta`\n",
        "Order by `yoy_delta` DESC\n",
        "Limit 5\n",
        "```\n",
        "**Validation:** Ask the model for two quick failure modes (e.g., missing years) and how to handle them."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WITH yr_sales AS (\n",
        "  SELECT\n",
        "    Sub_Category,\n",
        "    EXTRACT(YEAR FROM Order_Date) AS year,\n",
        "    SUM(Sales) AS total_sales\n",
        "  FROM\n",
        "    `[YOUR_PROJECT].superstore_data.sales`\n",
        "  WHERE\n",
        "    EXTRACT(YEAR FROM Order_Date) IN (2023, 2024)\n",
        "  GROUP BY\n",
        "    Sub_Category,\n",
        "    year\n",
        "),\n",
        "sales_pivot AS (\n",
        "  SELECT\n",
        "    Sub_Category,\n",
        "    MAX(IF(year = 2023, total_sales, 0)) AS sales_2023,\n",
        "    MAX(IF(year = 2024, total_sales, 0)) AS sales_2024\n",
        "  FROM\n",
        "    yr_sales\n",
        "  GROUP BY\n",
        "    Sub_Category\n",
        ")\n",
        "SELECT\n",
        "  Sub_Category,\n",
        "  sales_2023,\n",
        "  sales_2024,\n",
        "  (sales_2024 - sales_2023) AS yoy_delta\n",
        "FROM\n",
        "  sales_pivot\n",
        "ORDER BY\n",
        "  yoy_delta DESC\n",
        "LIMIT 5;\n"
      ],
      "metadata": {
        "id": "1L-wk6Rme4O-"
      },
      "id": "1L-wk6Rme4O-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c776dd89",
      "metadata": {
        "id": "c776dd89"
      },
      "source": [
        "## Part E — Window Functions (ROW_NUMBER, RANK, DENSE_RANK, LAG/LEAD, moving averages)\n",
        "**Aim:** Compare rows across partitions and time; compute trends and ranks without collapsing rows."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a5cf0c4",
      "metadata": {
        "id": "6a5cf0c4"
      },
      "source": [
        "### E1. Top product per region (ROW_NUMBER)\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: For each `Region`, return only the single highest-revenue `Sub_Category`.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "CTE `subcat_sales`: SUM(Sales) by `Region`, `Sub_Category`\n",
        "Add `ROW_NUMBER() OVER (PARTITION BY Region ORDER BY total_sales DESC)` as rn\n",
        "Final: filter `rn = 1`\n",
        "Output: `Region`, `Sub_Category`, `total_sales`\n",
        "Sort by `Region`\n",
        "```\n",
        "**Why `ROW_NUMBER` instead of `RANK`?** Ask the model to add a 2-sentence contrast."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WITH subcat_sales AS (\n",
        "  SELECT\n",
        "    Region,\n",
        "    Sub_Category,\n",
        "    SUM(Sales) AS total_sales\n",
        "  FROM\n",
        "    `[YOUR_PROJECT].superstore_data.sales`\n",
        "  GROUP BY\n",
        "    Region,\n",
        "    Sub_Category\n",
        "),\n",
        "ranked_subcat AS (\n",
        "  SELECT\n",
        "    Region,\n",
        "    Sub_Category,\n",
        "    total_sales,\n",
        "    ROW_NUMBER() OVER (PARTITION BY Region ORDER BY total_sales DESC) AS rn\n",
        "  FROM\n",
        "    subcat_sales\n",
        ")\n",
        "SELECT\n",
        "  Region,\n",
        "  Sub_Category,\n",
        "  total_sales\n",
        "FROM\n",
        "  ranked_subcat\n",
        "WHERE\n",
        "  rn = 1\n",
        "ORDER BY\n",
        "  Region;\n"
      ],
      "metadata": {
        "id": "YNtz2IH1e9Hc"
      },
      "id": "YNtz2IH1e9Hc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "552eb898",
      "metadata": {
        "id": "552eb898"
      },
      "source": [
        "### E2. YoY growth with LAG\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: Compute year-over-year revenue growth for 'Phones' sub-category.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "Steps:\n",
        "- Filter to `Sub_Category = 'Phones'`\n",
        "- Aggregate yearly revenue using EXTRACT(YEAR FROM Order_Date)\n",
        "- Add `LAG(yearly_revenue) OVER (ORDER BY year)` as `prev_revenue`\n",
        "- Compute `yoy_pct = 100.0 * (yearly_revenue - prev_revenue) / prev_revenue`\n",
        "Output: `year`, `yearly_revenue`, `prev_revenue`, `yoy_pct`\n",
        "Sort by `year` ASC\n",
        "```\n",
        "**Ask for**: a guard against divide-by-zero or NULL previous year."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WITH phones_yearly AS (\n",
        "  SELECT\n",
        "    EXTRACT(YEAR FROM Order_Date) AS year,\n",
        "    SUM(Sales) AS yearly_revenue\n",
        "  FROM\n",
        "    `[YOUR_PROJECT].superstore_data.sales`\n",
        "  WHERE\n",
        "    Sub_Category = 'Phones'\n",
        "  GROUP BY\n",
        "    year\n",
        ")\n",
        "SELECT\n",
        "  year,\n",
        "  yearly_revenue,\n",
        "  LAG(yearly_revenue) OVER (ORDER BY year) AS prev_revenue,\n",
        "  CASE\n",
        "    WHEN LAG(yearly_revenue) OVER (ORDER BY year) IS NULL\n",
        "         OR LAG(yearly_revenue) OVER (ORDER BY year) = 0\n",
        "    THEN NULL\n",
        "    ELSE 100.0 * (yearly_revenue - LAG(yearly_revenue) OVER (ORDER BY year))\n",
        "                / LAG(yearly_revenue) OVER (ORDER BY year)\n",
        "  END AS yoy_pct\n",
        "FROM\n",
        "  phones_yearly\n",
        "ORDER BY\n",
        "  year ASC;\n"
      ],
      "metadata": {
        "id": "SOSp3acRfCcZ"
      },
      "id": "SOSp3acRfCcZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ac0c3893",
      "metadata": {
        "id": "ac0c3893"
      },
      "source": [
        "### E3. 3‑month moving average (MA)\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: For the 'Corporate' segment, compute a 3-month moving average of monthly revenue.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "Steps:\n",
        "- Derive `month` via DATE_TRUNC(Order_Date, MONTH)\n",
        "- SUM(Sales) per `month`\n",
        "- Add `AVG(monthly_revenue) OVER (ORDER BY month ROWS BETWEEN 2 PRECEDING AND CURRENT ROW)` as `ma_3`\n",
        "Output: `month`, `monthly_revenue`, `ma_3`\n",
        "Sort by `month` ASC\n",
        "```\n",
        "**Tip:** Ask the model to include a 1‑line cost control note (e.g., restrict date range while iterating)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WITH monthly_sales AS (\n",
        "  SELECT\n",
        "    DATE_TRUNC(Order_Date, MONTH) AS month,\n",
        "    SUM(Sales) AS monthly_revenue\n",
        "  FROM\n",
        "    `[YOUR_PROJECT].superstore_data.sales`\n",
        "  WHERE\n",
        "    Segment = 'Corporate'\n",
        "  GROUP BY\n",
        "    month\n",
        ")\n",
        "SELECT\n",
        "  month,\n",
        "  monthly_revenue,\n",
        "  AVG(monthly_revenue) OVER (\n",
        "    ORDER BY month\n",
        "    ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n",
        "  ) AS ma_3\n",
        "FROM\n",
        "  monthly_sales\n",
        "ORDER BY\n",
        "  month ASC;\n"
      ],
      "metadata": {
        "id": "kJksYfdbfMH3"
      },
      "id": "kJksYfdbfMH3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a4e347a6",
      "metadata": {
        "id": "a4e347a6"
      },
      "source": [
        "## Part F — Debugging & Optimization Prompts\n",
        "**Aim:** Use the model as a rubber duck for error handling and performance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5d80923",
      "metadata": {
        "id": "e5d80923"
      },
      "source": [
        "### F1. Explain the error, propose a fix\n",
        "**Prompt:**\n",
        "```\n",
        "I ran this BigQuery SQL and got an error:\n",
        "[PASTE ERROR MESSAGE and the exact SQL here]\n",
        "Act as a BigQuery trouble‑shooter.\n",
        "1) Identify the root cause.\n",
        "2) Propose the smallest possible fix.\n",
        "3) Suggest a quick sanity check query to verify the fix.\n",
        "Return only the corrected SQL and a 2‑sentence rationale.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "-- Corrected SQL\n",
        "WITH monthly_sales AS (\n",
        "  SELECT\n",
        "    DATE_TRUNC(Order_Date, MONTH) AS month,\n",
        "    SUM(Sales) AS monthly_revenue\n",
        "  FROM\n",
        "    `[YOUR_PROJECT].superstore_data.sales`\n",
        "  WHERE\n",
        "    Segment = 'Corporate'\n",
        "  GROUP BY\n",
        "    month\n",
        ")\n",
        "SELECT\n",
        "  month,\n",
        "  monthly_revenue,\n",
        "  AVG(monthly_revenue) OVER (\n",
        "    ORDER BY month\n",
        "    ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n",
        "  ) AS ma_3\n",
        "FROM\n",
        "  monthly_sales\n",
        "ORDER BY\n",
        "  month ASC;\n"
      ],
      "metadata": {
        "id": "7hDb_POpfSbl"
      },
      "id": "7hDb_POpfSbl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "890814f8",
      "metadata": {
        "id": "890814f8"
      },
      "source": [
        "### F2. Reduce cost / improve speed\n",
        "**Prompt:**\n",
        "```\n",
        "Act as a BigQuery cost optimizer.\n",
        "Given this query (below), list 3 ways to reduce scanned bytes and improve performance without changing the business logic.\n",
        "[PASTE YOUR SQL HERE]\n",
        "Prioritize: partition filters, column pruning, pre-aggregations, and temporary results via CTEs.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Three ways to reduce scanned bytes and improve performance:\n",
        "\n",
        "Partition filters:\n",
        "\n",
        "If the Order_Date column is used and the table is date-partitioned, add a WHERE Order_Date BETWEEN ... clause to restrict the query to only the relevant months or years. This avoids scanning the entire table.\n",
        "\n",
        "Column pruning:\n",
        "\n",
        "Select only the columns you actually need (Sales, Order_Date, Segment, etc.) rather than using SELECT *. This reduces the amount of data read from storage.\n",
        "\n",
        "Pre-aggregations / CTEs:\n",
        "\n",
        "Aggregate data in a CTE or temporary table before applying window functions or joins. For example, compute monthly totals first, then calculate moving averages. This avoids repeatedly scanning the raw sales table."
      ],
      "metadata": {
        "id": "xrT40hFyfW-6"
      },
      "id": "xrT40hFyfW-6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1f88a2f5",
      "metadata": {
        "id": "1f88a2f5"
      },
      "source": [
        "## Part G — Validation & Counter‑examples (DIVE: Validate)\n",
        "**Aim:** Avoid “first‑answer fallacy” by testing alternatives."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ed05c0b",
      "metadata": {
        "id": "2ed05c0b"
      },
      "source": [
        "### G1. Ask for counter‑queries\n",
        "**Prompt:**\n",
        "```\n",
        "I concluded that 'Tables' is a high‑sales but negative‑profit sub-category due to high discounts.\n",
        "Create two alternative BigQuery SQL queries that could falsify or nuance this finding:\n",
        "- One that slices by region and time\n",
        "- One that controls for order priority or ship mode\n",
        "Return BigQuery SQL only, then a one-paragraph note on how to compare outcomes.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "-- Alternative 1: Slice by region and month to see if the negative profit holds across locations and time\n",
        "SELECT\n",
        "  Region,\n",
        "  FORMAT_DATE('%Y-%m', DATE_TRUNC(Order_Date, MONTH)) AS year_month,\n",
        "  SUM(Sales) AS total_sales,\n",
        "  SUM(Profit) AS total_profit,\n",
        "  AVG(Discount) AS avg_discount\n",
        "FROM\n",
        "  `[YOUR_PROJECT].superstore_data.sales`\n",
        "WHERE\n",
        "  Sub_Category = 'Tables'\n",
        "GROUP BY\n",
        "  Region,\n",
        "  year_month\n",
        "ORDER BY\n",
        "  Region,\n",
        "  year_month;\n",
        "\n",
        "-- Alternative 2: Control for Order Priority and Ship Mode to check if negative profit persists\n",
        "SELECT\n",
        "  Order_Priority,\n",
        "  Ship_Mode,\n",
        "  SUM(Sales) AS total_sales,\n",
        "  SUM(Profit) AS total_profit,\n",
        "  AVG(Discount) AS avg_discount\n",
        "FROM\n",
        "  `[YOUR_PROJECT].superstore_data.sales`\n",
        "WHERE\n",
        "  Sub_Category = 'Tables'\n",
        "GROUP BY\n",
        "  Order_Priority,\n",
        "  Ship_Mode\n",
        "ORDER BY\n",
        "  total_profit ASC;\n"
      ],
      "metadata": {
        "id": "DB2ZgG7dfctH"
      },
      "id": "DB2ZgG7dfctH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1e108a43",
      "metadata": {
        "id": "1e108a43"
      },
      "source": [
        "## Part H — Synthesis (DIVE: Extend)\n",
        "**Aim:** Turn analysis into business‑ready insights."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bf2bac2",
      "metadata": {
        "id": "0bf2bac2"
      },
      "source": [
        "### H1. Executive‑style summary\n",
        "**Prompt:**\n",
        "```\n",
        "Act as a business strategist.\n",
        "Based on the following metrics/figures (briefly summarize your results here), write a 4-sentence executive summary:\n",
        "- 1 sentence: what changed and by how much\n",
        "- 1 sentence: why it likely changed (drivers)\n",
        "- 1 sentence: recommended action (who/what/when)\n",
        "- 1 sentence: metric to monitor next\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Over the past quarter, total sales increased by 12% while net profit declined by 5%, indicating a divergence between revenue growth and profitability. This change is likely driven by higher discount rates and increased shipping costs, particularly in high-volume sub-categories like Tables and Phones. We recommend that the sales and operations teams review discount policies and optimize logistics within the next month to protect margins while sustaining growth. Moving forward, monitor the profit per sub-category and region to track whether interventions improve net profitability without harming sales momentum."
      ],
      "metadata": {
        "id": "KFjF3y0bfmNc"
      },
      "id": "KFjF3y0bfmNc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f3b5fdc9",
      "metadata": {
        "id": "f3b5fdc9"
      },
      "source": [
        "### H2. Convert final SQL into an automated job (optional)\n",
        "**Prompt (use only after your SQL is final):**\n",
        "```\n",
        "Convert my final BigQuery SQL into a Python script that can run as a scheduled job from Colab or Cloud Functions.\n",
        "Requirements:\n",
        "- Use python‑bigquery client\n",
        "- Parameterize date range\n",
        "- Write results to a destination table `[YOUR_PROJECT].analytics.outputs_kpi`\n",
        "- Add basic error handling & logging\n",
        "Return one complete runnable script.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "from google.api_core.exceptions import GoogleAPIError\n",
        "import logging\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s')\n",
        "\n",
        "# Optional: set your Google Cloud project if not already set in environment\n",
        "PROJECT_ID = \"your-project-id\"\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
        "\n",
        "# Initialize BigQuery client\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "# Parameters for date range\n",
        "START_DATE = \"2024-01-01\"\n",
        "END_DATE = \"2024-12-31\"\n",
        "\n",
        "# Final SQL (replace with your actual query)\n",
        "sql_query = f\"\"\"\n",
        "WITH filtered_sales AS (\n",
        "  SELECT\n",
        "    Order_Date,\n",
        "    Sub_Category,\n",
        "    Sales,\n",
        "    Profit\n",
        "  FROM\n",
        "    `[YOUR_PROJECT].superstore_data.sales`\n",
        "  WHERE\n",
        "    Order_Date BETWEEN '{START_DATE}' AND '{END_DATE}'\n",
        ")\n",
        "SELECT\n",
        "  Sub_Category,\n",
        "  SUM(Sales) AS total_sales,\n",
        "  SUM(Profit) AS total_profit,\n",
        "  AVG(Sales) AS avg_sale\n",
        "FROM\n",
        "  filtered_sales\n",
        "GROUP BY\n",
        "  Sub_Category\n",
        "ORDER BY\n",
        "  total_sales DESC\n",
        "\"\"\"\n",
        "\n",
        "# Destination table\n",
        "destination_table = f\"{PROJECT_ID}.analytics.outputs_kpi\"\n",
        "\n",
        "def run_query_and_save():\n",
        "    try:\n",
        "        logging.info(\"Starting BigQuery job...\")\n",
        "        job_config = bigquery.QueryJobConfig(\n",
        "            destination=destination_table,\n",
        "            write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE  # overwrite table\n",
        "        )\n",
        "\n",
        "        query_job = client.query(sql_query, job_config=job_config)\n",
        "        result = query_job.result()  # Waits for job to complete\n",
        "\n",
        "        logging.info(f\"Query completed successfully. {result.total_rows} rows written to {destination_table}\")\n",
        "        return True\n",
        "    except GoogleAPIError as e:\n",
        "        logging.error(f\"BigQuery API error: {e}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Unexpected error: {e}\")\n",
        "    return False\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    success = run_query_and_save()\n",
        "    if success:\n",
        "        logging.info(\"Job finished successfully.\")\n",
        "    else:\n",
        "        logging.error(\"Job failed.\")\n"
      ],
      "metadata": {
        "id": "6F2t2w8Qftq0"
      },
      "id": "6F2t2w8Qftq0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0148a198",
      "metadata": {
        "id": "0148a198"
      },
      "source": [
        "---\n",
        "## Submission checklist\n",
        "- [ ] Kept prompts precise and reproducible  \n",
        "- [ ] Captured at least **one** CTE query and **one** window function query  \n",
        "- [ ] Documented **two** validation attempts (counter‑queries or alternate slice)  \n",
        "- [ ] Wrote a 4‑sentence executive summary based on results  \n",
        "- [ ] (Optional) Converted final query into a scheduled job\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}